import numpy as np

"""
Sets up simulation classes to be reused in experiments.
"""

class Simulator:
    def __init__(self, N, D):
        """
        Initialize self and parameters for simulation.
        """

        self.N = N
        self.D = D

    def simulate(self, **kwargs):
        """
        Simulate data based on some parameters.

        Returns X (NxD), Y (Nx1), and Z (Nx1).
        """

        X = self._create_X(**kwargs)
        Z = self._create_Z(X, **kwargs)
        Y = self._create_Y(X, Z, **kwargs)
        return X, Y, Z

    def _create_X(self, **kwargs):
        """
        Generate X based on parameters.
        """

        raise NotImplementedError("Subclasses must define this")

    def _create_Y(self, X, Z, **kwargs):
        """
        Generate Y based on parameters, confounders X, and treatment Z.
        """

        raise NotImplementedError("Subclasses must define this")

    def _create_Z(self, X, **kwargs):
        """
        Generate Z based on parameters and confounders X.
        """

        raise NotImplementedError("Subclasses must define this")


class LinearSimulator(Simulator):
    """
    Simulates data coming from a confounded linear model. By default, this
    model is nonspatial. Subclasses add spatial effects.
    """

    def __init__(self, N, D):
        super().__init__(N, D)

    def _create_Y(self, X, Z, beta=None, tau=None, eps_sd=0.1):
        """
        Generates linear outcome from nonspatial confounders and treatment.
        Y is generated linearly by adding X times the given confounder effects
        to Z times the treatment effect and adding an error term.

        Any kwargs get passed to _create_data, which should be subclassed.

        Parameters
        ----------
        beta       : confounder effects
                     default: 2*ones(D, 1)

        tau        : treatment effect
                     default: 3

        Returns
        -------
        Y          : outcomes
        """

        if beta is None:
            beta = 2*np.ones((self.D, 1))
        if tau is None:
            tau = 3

        eps_y = np.random.normal(loc=0, scale=eps_sd, size=(self.N, 1))
        Y = np.dot(X, beta) + tau * Z + eps_y
        return Y

    def _create_X(self, x_sd=1):
        """
        Creates nonspatial data. X is generated by randomly choosing
        positive and negative integers in the interval [-2D, 2D] to use as
        means of normal distributions with SDs equal to x_sd (or elements of
        x_sd if it's a list).

        Parameters
        ----------
        x_sd       : standard deviation of confounders
                     default = 1

        Returns
        -------
        X          : confounders
        """

        if np.ndim(x_sd) == 0:
            x_sd = np.repeat(x_sd, self.D)

        # Confounders
        means = np.random.choice(np.arange(-2*self.D, 2*self.D + 1, 1, dtype=int),
                                 size=self.D, replace=False)
        X = np.zeros((self.N, self.D))
        for d in range(self.D):
            X[:, d] = np.random.normal(loc=means[d], scale=x_sd[d], size=(self.N, 1))

        return X

    def _create_Z(self, X, treat_prob=0.5, confound=0.2):
        """
        Creates nonspatial data. Z is an array of randomly assigned treatments
        according to treat_prob (N iid draws of Binomial(1, treat_prob)).

        Parameters
        ----------
        treat_prob : probability that a unit is treated
                     default = 0.5

        Returns
        -------
        Z          : treatment assigments
        """

        # Get means of X, then randomly choose covariates for each observation
        means = X.mean(0)
        var = np.random.choice(list(range(self.D)), size=(self.N, 1))

        # If an observation's covariate is greater than the mean, add to the
        # probability of treatment.
        # WARNING this doesn't feel right
        treat_probs = treat_prob*np.ones((self.N, 1)) \
                      + confound*X[X[:, var] > means]

        # Treatment assigned at random
        Z = np.random.binomial(1, treat_probs, size=(self.N, 1))
        return Z


class LinearAutoTreatment(LinearSimulator):
    def __init__(self, N, D):
        super().__init__(N, D)

    def _create_data(self, rho):
        """
        Parameters
        ----------
        rho       : level of spatial autocorrelation
        """

        pass

class LinearAutoOutcome(LinearSimulator):
    def __init__(self, N, D):
        super().__init__(N, D)

    # this class needs a simulate method to add spatial autocorrelation to Y

    def _create_data(self, rho):
        """
        Parameters
        ----------
        rho       : level of spatial autocorrelation
        """

        pass


class LinearAutoConfounder(LinearSimulator):
    def __init__(self, N, D):
        super().__init__(N, D)

    def _create_data(self, rho):
        """
        Parameters
        ----------
        rho       : level of spatial autocorrelation
        """

        pass


class NonlinearSimulator(Simulator):
    def __init__(self, N, D):
        super().__init__(N, D)

    def simulate(self):
        pass

    def _create_data(self):
        pass


class FriedmanSimulator(NonlinearSimulator):
    def __init__(self, N, D):
        if D < 4:
            D = 4  # minimum of 5 variables required for Friedman's function (Z is one)
        super().__init__(N, D)

    def simulate(self, eps_sd=0.1, treat_prob=0.5):
        X, Z = self._create_data(treat_prob)
        eps_y = np.random.normal(loc=0, scale=eps_sd, size=(self.N, 1))
        Y = 10*np.sin(np.pi*X[:, 0] * X[:, 1]) + 20*(X[:, 2] - 0.5)**2 + 10*X[:, 3] + 5*Z + eps_y

        return X, Y, Z

    def _create_data(self, treat_prob):
        """
        Defaults to nonspatial; subclasses implement spatial versions.
        """
        X = np.random.uniform(size=(self.N, self.D))
        Z = np.random.binomial(1, treat_prob, size=(self.N, 1))
        return X, Z
