import numpy as np
import libpysal

"""
Sets up simulation classes to be reused in experiments.
"""

class Simulator:
    def __init__(self, N, D):
        """
        Initialize self and parameters for simulation.
        """

        self.N = N
        self.D = D

    def simulate(self, **kwargs):
        """
        Simulate data based on some parameters.

        Returns X (NxD), Y (Nx1), and Z (Nx1).
        """

        X = self._create_X(**kwargs)
        Z = self._create_Z(X, **kwargs)
        Y = self._create_Y(X, Z, **kwargs)
        return X, Y, Z

    def _create_X(self, **kwargs):
        """
        Generate X based on parameters.
        """

        raise NotImplementedError("Subclasses must define this")

    def _create_Y(self, X, Z, **kwargs):
        """
        Generate Y based on parameters, confounders X, and treatment Z.
        """

        raise NotImplementedError("Subclasses must define this")

    def _create_Z(self, X, **kwargs):
        """
        Generate Z based on parameters and confounders X.
        """

        raise NotImplementedError("Subclasses must define this")


class LinearSimulator(Simulator):
    """
    Simulates data coming from a confounded linear model. By default, this
    model is nonspatial. The auto class attribute may be set to determine 
    which variables are spatially autocorrelated.
    """

    def __init__(self, N, D, auto=[], W=None):
        super().__init__(N, D)
        self.autoX = ("X" in auto or "x" in auto)
        self.autoY = ("Y" in auto or "y" in auto)
        self.autoZ = ("Z" in auto or "z" in auto)

        if len(auto) > 0 and W is None:
            raise ValueError("Need spatial weights matrix to generate " +
                             "autocorrelated data")

        if isinstance(W, libpysal.weights.weights.W):
            W = W.full()[0]
        else:
            W = np.zeros((N, N))
        self.W = W

    def _create_Y(self, X, Z, beta=None, tau=3, rho=1.2, eps_sd=0.1, sp_sd=0.1, **kwargs):
        """
        Generates linear outcome from confounders and treatment.
        Y is generated linearly by adding X times the given confounder effects
        to Z times the treatment effect and adding an error term.

        Parameters
        ----------
        beta       : confounder effects
                     default: 2*ones(D, 1)

        tau        : treatment effect
                     default: 3

        rho        : spatial effect
                     if not autocorrelated: n/a 
                     if autocorrelated: default 1.2

        eps_sd     : SD of nonspatial error term
                     default 0.1

        sp_sd      : SD of spatial error term
                     if not autocorrelated: n/a
                     if autocorrelated: default 0.1

        Returns
        -------
        Y          : outcomes
        """

        if beta is None:
            beta = 2 * np.ones((self.D, 1))

        eps_y = np.random.normal(loc=0, scale=eps_sd, size=(self.N, 1))

        if not self.autoY:
            sp_eps = np.zeros((self.N, 1))
        else:
            sp_eps = np.random.normal(loc=0, scale=sp_sd, size=(self.N, 1))
        Y = np.dot(X, beta) + tau*Z + np.dot(np.linalg.pinv(np.eye(self.N) - rho*self.W), sp_eps) + eps_y
        return Y

    def _create_X(self, x_sd=1, x_sp=0.9, **kwargs):
        """
        Creates confounders. X is generated by randomly choosing
        positive and negative integers in the interval [-2D, 2D] to use as
        means of normal distributions with SDs equal to x_sd (or elements of
        x_sd if it's a list).

        Parameters
        ----------
        x_sd       : standard deviation of confounders
                     default = 1

        x_sp       : spatial autocorrelation parameter
                     default 0.9

        Returns
        -------
        X          : confounders
        """

        if np.ndim(x_sd) == 0:
            x_sd = np.repeat(x_sd, self.D)

        # Confounders
        means = np.random.choice(np.arange(-2*self.D, 2*self.D + 1, 1, dtype=int),
                                 size=self.D, replace=False)
        X = np.zeros((self.N, self.D))

        for d in range(self.D):
            X[:, d] = np.random.normal(loc=means[d], scale=x_sd[d], size=(self.N,))

        if self.autoX:
            X[:, d] = np.dot(np.linalg.pinv(np.eye(self.N) - x_sp*self.W), X[:, d])

        return X

    def _create_Z(self, X, treat_prob=0.5, confound=0.2, **kwargs):
        """
        Creates treatment. Z is an array of randomly assigned treatments
        according to treat_prob (N iid draws of Binomial(1, treat_prob)).

        Parameters
        ----------
        treat_prob : probability that a unit is treated
                     default = 0.5

        Returns
        -------
        Z          : treatment assigments
        """

        # Get means of X, then randomly choose covariates for each observation
        means = X.mean(0)
        var = np.random.choice(list(range(self.D)), size=(self.N, 1))

        # If an observation's covariate is greater than the mean, add to the
        # probability of treatment.
        # WARNING this doesn't feel right
        mask = np.zeros((self.N, 1))
        for i in range(mask.shape[0]):
            mask[i] = X[i, var[i]] > means[var[i]]

        treat_probs = treat_prob + confound*mask

        # Treatment assigned at random
        Z = np.random.binomial(1, treat_probs, size=(self.N, 1))

        if self.autoZ:
            slag = np.dot(self.W, Z)
            Z = np.where(slag > 2, 1, 0)  # autocorrelate
        return Z


class NonlinearSimulator(Simulator):
    def __init__(self, N, D, auto=[], W=None):
        super().__init__(N, D)
        self.autoX = ("X" in auto or "x" in auto)
        self.autoY = ("Y" in auto or "y" in auto)
        self.autoZ = ("Z" in auto or "z" in auto)

        if len(auto) > 0 and W is None:
            raise ValueError("Need spatial weights matrix to generate " +
                             "autocorrelated data")

        if isinstance(W, libpysal.weights.weights.W):
            W = W.full()[0]
        else:
            W = np.zeros((N, N))
        self.W = W

    def _create_X(self):
        pass

    def _create_Y(self):
        pass

    def _create_Z(self):
        pass


class FriedmanSimulator(NonlinearSimulator):
    def __init__(self, N, D):
        if D < 4:
            D = 4  # minimum of 5 variables required for Friedman's function (Z is one)
        super().__init__(N, D)

    def simulate(self, eps_sd=0.1, treat_prob=0.5):
        X, Z = self._create_data(treat_prob)
        eps_y = np.random.normal(loc=0, scale=eps_sd, size=(self.N, 1))
        Y = 10*np.sin(np.pi*X[:, 0] * X[:, 1]) + 20*(X[:, 2] - 0.5)**2 + 10*X[:, 3] + 5*Z + eps_y

        return X, Y, Z

    def _create_data(self, treat_prob):
        """
        Defaults to nonspatial; subclasses implement spatial versions.
        """
        X = np.random.uniform(size=(self.N, self.D))
        Z = np.random.binomial(1, treat_prob, size=(self.N, 1))
        return X, Z


if __name__ == "__main__":
    from rundown import LinearSimulator
    from libpysal.weights import lat2W

    Nlat = 30
    N = Nlat**2
    D = 3

    # Test nonspatial linear
    L = LinearSimulator(N, D)
    X, Y, Z = L.simulate(confound=0)  # no confounding
    X, Y, Z = L.simulate()            # confounding

    # Test spatial autocorrelated linear
    W = lat2W(Nlat, Nlat)
    L = LinearSimulator(N, D, auto="x", W=W)
    X, Y, Z = L.simulate(confound=0)  # no confounding
    X, Y, Z = L.simulate()            # confounding

    L = LinearSimulator(N, D, auto="y", W=W)
    X, Y, Z = L.simulate(confound=0)  # no confounding
    X, Y, Z = L.simulate()            # confounding

    L = LinearSimulator(N, D, auto="z", W=W)
    X, Y, Z = L.simulate(confound=0)  # no confounding
    X, Y, Z = L.simulate()            # confounding
